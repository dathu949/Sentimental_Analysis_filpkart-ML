# -*- coding: utf-8 -*-
"""Sentimental_Analysis_FK_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gynILAq-TukeM6I9S2AFyen0ANvrC2q6
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.model_selection import cross_val_score,cross_validate,StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
import sklearn

#Load the dataframe
data = pd.read_csv('data.csv')
data.head()

#Check the shape of data
data.shape

#check the null values
data.isnull().sum()

#Percentage of null values
(data.isnull().sum()/ len(data)) * 100

### Insight:
### From the above we can infer that null/missing values less than 1% apart from date column.
### we can remove them or replace with mean or median.
### Date column alone we will handle, as it is slightly greater than 5%

# Handle the null values
## We can drop the null values
data.dropna(subset=['Reviewer Name','Review Title','Place of Review','Up Votes','Down Votes','Review text'],
            inplace=True)
# replace the null values of month with ffill / bfill
data['Month'] = data['Month'].fillna(data['Month'].ffill())

# Check the data again
data.head()

data.isnull().sum()

import nltk
nltk.download('stopwords')

from nltk.stem.snowball import stopwords
import re
# Data Preprocessing
stop_words = set(stopwords.words('english'))
def clean_text(text):
  #change all the character to lower case
  text = str(text).lower()
  #Remove the special characters or punctuations
  text = re.sub(r'[^\w\d\s]', ' ',text)
  text = re.sub(r',', ' ',text)
  text = re.sub(r'\s+', ' ',text)
  text = re.sub(r'^\s+|\s+?$', '',text)
  #remove stop words
  text = ''.join(term for term in text.split() if term not in stop_words)
  return text

text_cols = ['Review text']
for col in text_cols:
  data[col]= data[col].apply(clean_text)

nltk.download('wordnet')

## Lemmetization

from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
def lemmatize_text(text):
  text = ' '.join(lemmatizer.lemmatize(term,pos='v') for term in str(text).split())
  return text

for col in text_cols:
  data[col] = data[col].apply(lemmatize_text)

# Divide the data into features and target
X = data['Review text']
data['Sentiment'] = data['Ratings'].apply(lambda x:'positive' if x>=4 else 'Negative')
y = data.Sentiment.map({'positive':0,'Negative':1})

# Divide the data into train test split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

## TF-IDF
tfidf = TfidfVectorizer(max_features=5000,ngram_range=(1, 2))
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

models = {
    "Logistic Regr": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(),
    "SVM-Linear": SVC(kernel='linear'),
    "SVM-RBF": SVC(kernel='rbf'),
    "Naive Bayes": MultinomialNB(),
    "Decision-Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "XGB": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),
    "MLP": MLPClassifier(max_iter=1000)
}


for name, model in models.items():
    model.fit(X_train_tfidf,y_train)
    y_pred = model.predict(X_test_tfidf)
    print(name)
    print(classification_report(y_test, y_pred))
    print(confusion_matrix(y_test,y_pred))

from sklearn.pipeline import Pipeline
pipeline = Pipeline([
    ('tfidf',TfidfVectorizer(max_features=4800,ngram_range=(1,2),min_df = 5,stop_words='english')),
    ('clf',LogisticRegression(class_weight='balanced',max_iter = 1000))
])
pipeline.fit(X_train,y_train)


# In[35]:


# export with joblib:
import joblib
joblib.dump(pipeline,'sentiment_pipeline.joblib')

#!pip install streamlit

#!pip install mlflow optuna
import streamlit as st, joblib
model = joblib.load('sentiment_pipeline.joblib')
st.title("Review Sentiment")
txt = st.text_area('Paste review')
if st.button('predict'):
    pred = model.predict([txt])[0]
    st.write('Sentiment:',pred)

