# -*- coding: utf-8 -*-
"""SentimentAnalysis_flipkart_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W8WiwzmWgje0R5Q4ABB0iR4huSJwrybD
"""

#import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.model_selection import cross_val_score,cross_validate,StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from optuna.integration.mlflow import MLflowCallback
import time
import joblib
import os
import mlflow
import optuna
import sklearn
# Create a new experiment
mlflow.set_experiment("Hyperparameter Tunning Experiment")

#Load the dataframe
data = pd.read_csv('data.csv')
data.head()

#Check the shape of data
data.shape

#check the null values
data.isnull().sum()

#Percentage of null values
(data.isnull().sum()/ len(data)) * 100

### Insight:
### From the above we can infer that null/missing values less than 1% apart from date column.
### we can remove them or replace with mean or median.
### Date column alone we will handle, as it is slightly greater than 5%

# Handle the null values
## We can drop the null values
data.dropna(subset=['Reviewer Name','Review Title','Place of Review','Up Votes','Down Votes','Review text'],
            inplace=True)
# replace the null values of month with ffill / bfill
data['Month'] = data['Month'].fillna(data['Month'].ffill())

# Check the data again
data.head()

data.isnull().sum()

import nltk
nltk.download('stopwords')

from nltk.stem.snowball import stopwords
import re
# Data Preprocessing
stop_words = set(stopwords.words('english'))
def clean_text(text):
  #change all the character to lower case
  text = str(text).lower()
  #Remove the special characters or punctuations
  text = re.sub(r'[^\w\d\s]', ' ',text)
  text = re.sub(r',', ' ',text)
  text = re.sub(r'\s+', ' ',text)
  text = re.sub(r'^\s+|\s+?$', '',text)
  #remove stop words
  text = ''.join(term for term in text.split() if term not in stop_words)
  return text

text_cols = ['Review text']
for col in text_cols:
  data[col]= data[col].apply(clean_text)

nltk.download('wordnet')

## Lemmetization

from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
def lemmatize_text(text):
  text = ' '.join(lemmatizer.lemmatize(term,pos='v') for term in str(text).split())
  return text

for col in text_cols:
  data[col] = data[col].apply(lemmatize_text)

# Divide the data into features and target
X = data['Review text']
data['Sentiment'] = data['Ratings'].apply(lambda x:'positive' if x>=4 else 'Negative')
y = data.Sentiment

# Divide the data into train test split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

## TF-IDF
# from sklearn.feature_extraction.text import TfidfVectorizer
# tfidf = TfidfVectorizer(max_features=5000,ngram_range=(1, 2))
# X_train_tfidf = tfidf.fit_transform(X_train)
# X_test_tfidf = tfidf.transform(X_test)

from sklearn.pipeline import Pipeline
pipeline = Pipeline([('tfidf',TfidfVectorizer()),
 ('clf',LogisticRegression())])

#pipeline = Pipeline(
#     [
#         ('Scaler', StandardScaler()),
#         ('Model', KNeighborsClassifier())
#     ]
# )

def objective_rf(trial):

    # Random Forest hyperparameters
    pipeline.set_params(
    tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), min_df=5, stop_words='english'),
    clf=RandomForestClassifier(
        n_estimators=trial.suggest_int('n_estimators', 100, 500, step=50),
        # ... other suggested params ...
        random_state=42,
        n_jobs=-1
    ))

    skf = StratifiedKFold(n_splits=5, shuffle=True)
    score = cross_val_score(
        pipeline,
        X_train,
        y_train,
        scoring='accuracy',
        cv=skf
    ).mean()

    return score

def objective_lr(trial):

    # Random Forest hyperparameters
    pipeline.set_params(
    tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), min_df=5, stop_words='english'),
    clf=LogisticRegression(
          # Regularization strength: lower values mean stronger regularization
          C=trial.suggest_float('C', 1e-5, 100, log=True),
          # Solver choice: 'liblinear' and 'lbfgs' are standard for text
          solver=trial.suggest_categorical('solver', ['liblinear', 'lbfgs']),
          max_iter=1000,
          class_weight='balanced',
          random_state=42
        ))

    skf = StratifiedKFold(n_splits=5, shuffle=True)
    score = cross_val_score(
        pipeline,
        X_train,
        y_train,
        scoring='accuracy',
        cv=skf,
        n_jobs = -1
    ).mean()

    return score

def objective_multinb(trial):

    # Random Forest hyperparameters
    pipeline.set_params(
    tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), min_df=5, stop_words='english'),
    clf=MultinomialNB(
            # Alpha is the smoothing parameter (0.0 means no smoothing)
            alpha=trial.suggest_float('alpha', 1e-3, 10.0, log=True),
            # fit_prior determines whether to learn class prior probabilities
            fit_prior=trial.suggest_categorical('fit_prior', [True, False])
        ))

    skf = StratifiedKFold(n_splits=5, shuffle=True)
    score = cross_val_score(
        pipeline,
        X_train,
        y_train,
        scoring='accuracy',
        cv=skf,
        n_jobs = -1
    ).mean()
    return score

def objective_svc(trial):

    # Random Forest hyperparameters
    pipeline.set_params(
    tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), min_df=5, stop_words='english'),
    clf=SVC(
            # Regularization parameter
            C=trial.suggest_float('C', 0.1, 10.0, log=True),
            # Kernel type
            kernel=trial.suggest_categorical('kernel', ['linear', 'rbf']),
            # Kernel coefficient (only for 'rbf')
            gamma=trial.suggest_categorical('gamma', ['scale', 'auto']),
            # Useful for imbalanced text classes
            class_weight='balanced',
            random_state=42,
            max_iter=2000 # Prevents infinite loops on non-converging trials
        )
    )

    skf = StratifiedKFold(n_splits=5, shuffle=True)
    score = cross_val_score(
        pipeline,
        X_train,
        y_train,
        scoring='accuracy',
        cv=skf,
        n_jobs = -1
    ).mean()
    return score

with mlflow.start_run(run_name="study") as run:
    # Log the experiment settings
    n_trials = 30
    mlflow.log_param("n_trials", n_trials)

    study = optuna.create_study(direction="minimize")
    study.optimize(objective_svc, n_trials=n_trials)

    # Log the best trial and its run ID
    mlflow.log_params(study.best_trial.params)
    mlflow.log_metrics({"best_error": study.best_value})
    if best_run_id := study.best_trial.user_attrs.get("run_id"):
        mlflow.log_param("best_child_run_id", best_run_id)

#!pip install optuna-integration[mlflow]



# Model Building

results = {}
model_dict = {}

objectives = {
    'logistic regression':objective_lr,
    'svc':objective_svc,
    'RandomForest':objective_rf,
    'multinb':objective_multinb,
}
for model_name,obj_fn in objectives.items():
    print(f"\n--- Optimizing {model_name} ---")

    # # Disable autologging once
    # mlflow.sklearn.autolog(disable = True)

    mlflow_cb = MLflowCallback(
        tracking_uri=None,              # Auto-detect (str/None)
        metric_name="cv_accuracy",      # Primary metric (str)
        mlflow_kwargs={                 # **MLflow start_run() kwargs**
            "nested": True              # Child runs under parent
        }
    )

    # Create Optuna study
    study = optuna.create_study(direction="maximize")

    # Train the final model
    start_fit = time.time()
    study.optimize(obj_fn, n_trials=20, callbacks=[mlflow_cb])
    fit_time = time.time() - start_fit

    print(f"Best CV accuracy for {model_name}: {study.best_value:.4f}")
    best_params = study.best_params
    results[model_name] = {"best_params": best_params, "best_cv_accuracy": study.best_value}

    # Fit the pipeline with the best parameters
    if model_name == "logistic regression":
        # 1. Update TF-IDF (The Transformer)
        pipeline.set_params(
            tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), stop_words='english'),

            # 2. Update Logistic Regression (The Classifier)
            # Use 'clf__' to match your pipeline's second step
            clf__C=best_params["C"],
            clf__solver=best_params.get("solver", "liblinear"), # Default to liblinear for text
            clf__max_iter=1000,
            clf__class_weight='balanced',
            clf__random_state=42
        )
    elif model_name == "RandomForest":
        # 1. Update TF-IDF (The Transformer)
        # We use best_params if you tuned TF-IDF, otherwise use your fixed settings
        pipeline.set_params(
            tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), stop_words='english'),

            # 2. Update Random Forest (The Classifier)
            # Ensure 'clf__' matches the name of your second step in the Pipeline
            clf__n_estimators=best_params["n_estimators"],
            clf__n_jobs=-1,
            clf__random_state=42
        )
    elif model_name == "svc":
        # 1. Update TF-IDF (The Transformer)
        pipeline.set_params(
            tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), stop_words='english')
        )

        # 2. Update SVC (The Classifier)
        # We use .get() for gamma to avoid errors if it wasn't suggested in a linear trial
        pipeline.set_params(
            clf__C=best_params["C"],
            clf__kernel=best_params["kernel"],
            clf__gamma=best_params["gamma"],
            clf__class_weight='balanced',
            clf__random_state=42,
            clf__max_iter=2000
        )
    elif model_name == "multinb":
        # 1. Update TF-IDF
        pipeline.set_params(
            tfidf=TfidfVectorizer(max_features=4800, ngram_range=(1,2), stop_words='english')
        )
        # 2. Update MultinomialNB (The Classifier)
        # alpha is the primary hyperparameter for Naive Bayes
        pipeline.set_params(
            clf__alpha=best_params["alpha"],
            clf__fit_prior=best_params.get("fit_prior", True)
        )



    # # Enable autologging once
    # mlflow.sklearn.autolog()

    # Train the final model
    pipeline.fit(X_train, y_train)

    # Evaluate on test data
    start_test = time.time()
    y_pred = pipeline.predict(X_test)
    test_time = time.time() - start_test

    train_acc = pipeline.score(X_train, y_train)
    test_acc = accuracy_score(y_test, y_pred)

    print(f"{model_name} Training Accuracy: {train_acc:.4f}, Testing Accuracy: {test_acc:.4f}")
    print(f"{model_name} Fit Time: {fit_time:.2f}s, Test Time: {test_time:.2f}s")

    # Save model manually to track model size
    model_path = f"{model_name}_final_model.pkl"
    joblib.dump(pipeline, model_path)
    model_size = os.path.getsize(model_path)
    for i, model in enumerate(objectives.keys()):
        model_dict[model] = i

    # for i, scaler_type in enumerate(['standard', 'minmax']):
    #     scaler_dict[scaler_type] = i

    mlflow.log_metric(f"model_id", model_dict[model_name])
   # mlflow.log_metric(f"Scalar_id", scaler_dict[scaler_type])
    mlflow.log_metric(f"train_accuracy", train_acc)
    mlflow.log_metric(f"test_accuracy", test_acc)
    mlflow.log_metric(f"train_time", fit_time)
    mlflow.log_metric(f"test_time", test_time)
    mlflow.log_metric(f"model_size", model_size)
    mlflow.sklearn.log_model(pipeline, name=f"{model_name}Sentimental_Analysis") #, registered_model_name = f"Iris_{model_name}_Best")
    os.remove(model_path)

    results[model_name].update({
        "train_accuracy": train_acc,
        "test_accuracy": test_acc,
        "fit_time": fit_time,
        "test_time": test_time,
        "model_size_bytes": model_size
    })
    mlflow.end_run()

# Summary
print("\n--- Summary ---")
for model_name, res in results.items():
    print(f"{model_name}: CV Acc={res['best_cv_accuracy']:.4f}, Train Acc={res['train_accuracy']:.4f}, "
          f"Test Acc={res['test_accuracy']:.4f}, Fit Time={res['fit_time']:.2f}s, "
          f"Model Size={res['model_size_bytes']} bytes")

#!pip install mlflow optuna
import streamlit as st, joblib
model = joblib.load('sentiment_pipeline.joblib')
st.title("Review Sentiment")
txt = st.text_area('Paste review')
if st.button('predict'):
    pred = model.predict([txt])[0]
    st.write('Sentiment:',pred)




